{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f430d80c-e820-4bc0-9f83-a4aba19ef917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=4318321526858260#setting/sparkui/0708-192940-tso4v0um/driver-3379684132182351611\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=4318321526858260#setting/sparkui/0708-192940-tso4v0um/driver-3379684132182351611\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark= SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eda47e8c-5551-434a-b128-73108f18eed0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- id: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n+---------+----------+--------+-----+------+------+\n|firstname|middlename|lastname|id   |gender|salary|\n+---------+----------+--------+-----+------+------+\n|James    |          |Smith   |36636|M     |3000  |\n|Michael  |Rose      |        |40288|M     |4000  |\n|Robert   |          |Williams|42114|M     |4000  |\n|Maria    |Anne      |Jones   |39192|F     |4000  |\n|Jen      |Mary      |Brown   |     |F     |-1    |\n+---------+----------+--------+-----+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "\n",
    "data2 = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "  ]\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"firstname\",StringType(),True), \\\n",
    "    StructField(\"middlename\",StringType(),True), \\\n",
    "    StructField(\"lastname\",StringType(),True), \\\n",
    "    StructField(\"id\", StringType(), True), \\\n",
    "    StructField(\"gender\", StringType(), True), \\\n",
    "    StructField(\"salary\", IntegerType(), True) \\\n",
    "  ])\n",
    "\n",
    "df = spark.createDataFrame(data=data2,schema=schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d8cf973-63c8-4040-9abc-3085617d43a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- id: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n+---------+----------+--------+-----+------+------+\n|firstname|middlename|lastname|id   |gender|salary|\n+---------+----------+--------+-----+------+------+\n|James    |          |Smith   |36636|M     |3000  |\n|Michael  |Rose      |        |40288|M     |4000  |\n|Robert   |          |Williams|42114|M     |4000  |\n|Maria    |Anne      |Jones   |39192|F     |4000  |\n|Jen      |Mary      |Brown   |     |F     |-1    |\n+---------+----------+--------+-----+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "  ]\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"firstname\",StringType(),True), \\\n",
    "    StructField(\"middlename\",StringType(),True), \\\n",
    "    StructField(\"lastname\",StringType(),True), \\\n",
    "    StructField(\"id\", StringType(), True), \\\n",
    "    StructField(\"gender\", StringType(), True), \\\n",
    "    StructField(\"salary\", IntegerType(), True) \\\n",
    "  ])\n",
    "\n",
    "df = spark.createDataFrame(data=data,schema=schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8b7450f-4bf1-403a-ad25-52aa9e3d6d7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|        |\n|   Robert|Williams|\n|    Maria|   Jones|\n|      Jen|   Brown|\n+---------+--------+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|        |\n|   Robert|Williams|\n|    Maria|   Jones|\n|      Jen|   Brown|\n+---------+--------+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|        |\n|   Robert|Williams|\n|    Maria|   Jones|\n|      Jen|   Brown|\n+---------+--------+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|        |\n|   Robert|Williams|\n|    Maria|   Jones|\n|      Jen|   Brown|\n+---------+--------+\n\n+---------+----------+--------+\n|firstname|middlename|lastname|\n+---------+----------+--------+\n|    James|          |   Smith|\n|  Michael|      Rose|        |\n|   Robert|          |Williams|\n|    Maria|      Anne|   Jones|\n|      Jen|      Mary|   Brown|\n+---------+----------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select('firstname','lastname').show()\n",
    "df.select(df.firstname, df.lastname).show()\n",
    "df.select(df['firstname'], df['lastname']).show()\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "df.select(col('firstname'), col('lastname')).show()\n",
    "\n",
    "df.select(df.colRegex(\"`^.*name*`\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52afb145-b7a9-48ce-9e84-15548a320dd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|       dob|gender|salary|\n+---------+----------+--------+----------+------+------+\n|    James|          |   Smith|1991-04-01|     M|  3000|\n|  Michael|      Rose|        |2000-05-19|     M|  4000|\n|   Robert|          |Williams|1978-09-05|     M|  4000|\n|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n+---------+----------+--------+----------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [('James','','Smith','1991-04-01','M',3000),\n",
    "  ('Michael','Rose','','2000-05-19','M',4000),\n",
    "  ('Robert','','Williams','1978-09-05','M',4000),\n",
    "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
    "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "df = spark.createDataFrame(data=data, schema = columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f7f654b-858b-47b4-b87f-003dbaec93fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|       dob|gender|salary|\n+---------+----------+--------+----------+------+------+\n|    James|          |   Smith|1991-04-01|     M|  3000|\n|  Michael|      Rose|        |2000-05-19|     M|  4000|\n|   Robert|          |Williams|1978-09-05|     M|  4000|\n|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n+---------+----------+--------+----------+------+------+\n\n+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|       dob|gender|salary|\n+---------+----------+--------+----------+------+------+\n|    James|          |   Smith|1991-04-01|     M|300000|\n|  Michael|      Rose|        |2000-05-19|     M|400000|\n|   Robert|          |Williams|1978-09-05|     M|400000|\n|    Maria|      Anne|   Jones|1967-12-01|     F|400000|\n|      Jen|      Mary|   Brown|1980-02-17|     F|  -100|\n+---------+----------+--------+----------+------+------+\n\n+---------+----------+--------+----------+------+------+-----------+\n|firstname|middlename|lastname|       dob|gender|salary|CopieColumn|\n+---------+----------+--------+----------+------+------+-----------+\n|    James|          |   Smith|1991-04-01|     M|  3000|      -3000|\n|  Michael|      Rose|        |2000-05-19|     M|  4000|      -4000|\n|   Robert|          |Williams|1978-09-05|     M|  4000|      -4000|\n|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|      -4000|\n|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|          1|\n+---------+----------+--------+----------+------+------+-----------+\n\n+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|date      |gender|salary|\n+---------+----------+--------+----------+------+------+\n|James    |          |Smith   |1991-04-01|M     |3000  |\n|Michael  |Rose      |        |2000-05-19|M     |4000  |\n|Robert   |          |Williams|1978-09-05|M     |4000  |\n|Maria    |Anne      |Jones   |1967-12-01|F     |4000  |\n|Jen      |Mary      |Brown   |1980-02-17|F     |-1    |\n+---------+----------+--------+----------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('salary', col('salary').cast('Integer')).show()\n",
    "df.withColumn('salary', col('salary')*100).show()\n",
    "df.withColumn('CopieColumn', col('salary')*-1).show()\n",
    "df.withColumnRenamed('dob', 'date')\\\n",
    "  .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be026d31-7c77-4e01-81fe-3caa89df4c97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+\n|firstname|middlename|lastname|       dob|gender|\n+---------+----------+--------+----------+------+\n|    James|          |   Smith|1991-04-01|     M|\n|  Michael|      Rose|        |2000-05-19|     M|\n|   Robert|          |Williams|1978-09-05|     M|\n|    Maria|      Anne|   Jones|1967-12-01|     F|\n|      Jen|      Mary|   Brown|1980-02-17|     F|\n+---------+----------+--------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.drop('salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bacb413-5a00-4791-9f5e-6527cfaa0573",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- languages: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- state: string (nullable = true)\n |-- gender: string (nullable = true)\n\n+----------------------+------------------+-----+------+\n|name                  |languages         |state|gender|\n+----------------------+------------------+-----+------+\n|{James, , Smith}      |[Java, Scala, C++]|OH   |M     |\n|{Anna, Rose, }        |[Spark, Java, C++]|NY   |F     |\n|{Julia, , Williams}   |[CSharp, VB]      |OH   |F     |\n|{Maria, Anne, Jones}  |[CSharp, VB]      |NY   |M     |\n|{Jen, Mary, Brown}    |[CSharp, VB]      |NY   |M     |\n|{Mike, Mary, Williams}|[Python, VB]      |OH   |M     |\n+----------------------+------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType,StructField\n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
    "data = [\n",
    "    ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
    "    ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
    "    ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\")\n",
    " ]\n",
    "\n",
    "schema = StructType([\n",
    "     StructField('name', StructType([\n",
    "        StructField('firstname', StringType(), True),\n",
    "        StructField('middlename', StringType(), True),\n",
    "         StructField('lastname', StringType(), True)\n",
    "     ])),\n",
    "     StructField('languages', ArrayType(StringType()), True),\n",
    "     StructField('state', StringType(), True),\n",
    "     StructField('gender', StringType(), True)\n",
    " ])\n",
    "\n",
    "df = spark.createDataFrame(data = data, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6adef90e-d8df-4d4d-80b5-87f31738c32c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n|name                |languages         |state|gender|\n+--------------------+------------------+-----+------+\n|{Anna, Rose, }      |[Spark, Java, C++]|NY   |F     |\n|{Maria, Anne, Jones}|[CSharp, VB]      |NY   |M     |\n|{Jen, Mary, Brown}  |[CSharp, VB]      |NY   |M     |\n+--------------------+------------------+-----+------+\n\n+--------------------+------------------+-----+------+\n|name                |languages         |state|gender|\n+--------------------+------------------+-----+------+\n|{Anna, Rose, }      |[Spark, Java, C++]|NY   |F     |\n|{Maria, Anne, Jones}|[CSharp, VB]      |NY   |M     |\n|{Jen, Mary, Brown}  |[CSharp, VB]      |NY   |M     |\n+--------------------+------------------+-----+------+\n\n+----------------------+------------------+-----+------+\n|name                  |languages         |state|gender|\n+----------------------+------------------+-----+------+\n|{James, , Smith}      |[Java, Scala, C++]|OH   |M     |\n|{Julia, , Williams}   |[CSharp, VB]      |OH   |F     |\n|{Mike, Mary, Williams}|[Python, VB]      |OH   |M     |\n+----------------------+------------------+-----+------+\n\n+----------------------+------------------+-----+------+\n|name                  |languages         |state|gender|\n+----------------------+------------------+-----+------+\n|{James, , Smith}      |[Java, Scala, C++]|OH   |M     |\n|{Julia, , Williams}   |[CSharp, VB]      |OH   |F     |\n|{Mike, Mary, Williams}|[Python, VB]      |OH   |M     |\n+----------------------+------------------+-----+------+\n\n+--------------------+------------------+-----+------+\n|                name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|\n|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n|{Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n+--------------------+------------------+-----+------+\n\n+-------------------+------------------+-----+------+\n|               name|         languages|state|gender|\n+-------------------+------------------+-----+------+\n|     {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n|{Julia, , Williams}|      [CSharp, VB]|   OH|     F|\n+-------------------+------------------+-----+------+\n\n+-------------------+------------------+-----+------+\n|               name|         languages|state|gender|\n+-------------------+------------------+-----+------+\n|     {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n|{Julia, , Williams}|      [CSharp, VB]|   OH|     F|\n+-------------------+------------------+-----+------+\n\n+----------------------+------------------+-----+------+\n|name                  |languages         |state|gender|\n+----------------------+------------------+-----+------+\n|{James, , Smith}      |[Java, Scala, C++]|OH   |M     |\n|{Mike, Mary, Williams}|[Python, VB]      |OH   |M     |\n+----------------------+------------------+-----+------+\n\n+--------------------+------------------+-----+------+\n|                name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|\n| {Julia, , Williams}|      [CSharp, VB]|   OH|     F|\n|{Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n+--------------------+------------------+-----+------+\n\n+--------------------+------------------+-----+------+\n|                name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|\n| {Julia, , Williams}|      [CSharp, VB]|   OH|     F|\n|{Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n+--------------------+------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.state!='OH').show(truncate=False)\n",
    "df.filter(df.state!='OH').show(truncate=False)\n",
    "df.filter(df.state=='OH').show(truncate=False)\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "df.filter(col('state')=='OH')\\\n",
    "  .show(truncate=False)\n",
    "\n",
    "df.filter(\"gender=='M'\").show()\n",
    "df.filter(\"gender!='M'\").show()\n",
    "df.filter(\"gender<> 'M'\").show()\n",
    "\n",
    "df.filter( (df.state=='OH') & (df.gender=='M'))\\\n",
    "  .show(truncate=False)\n",
    "\n",
    "li=['OH', 'CA', 'DE']\n",
    "df.filter(df.state.isin(li)).show()\n",
    "\n",
    "df.filter(df.state.like(\"%O%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73dc2242-095f-4d36-b2c2-79c4d8609a5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- ID: string (nullable = true)\n |-- FIRSTNAME: string (nullable = true)\n |-- MIDDLENAME: string (nullable = true)\n |-- LASTNAME: string (nullable = true)\n |-- ID_EMPRESA: string (nullable = true)\n |-- GENDER: string (nullable = true)\n |-- SALARIO: integer (nullable = true)\n\n+---+---------+----------+--------+----------+------+-------+\n|ID |FIRSTNAME|MIDDLENAME|LASTNAME|ID_EMPRESA|GENDER|SALARIO|\n+---+---------+----------+--------+----------+------+-------+\n|1  |James    |          |Smith   |36636     |M     |3000   |\n|2  |Michael  |Rose      |        |40288     |M     |4000   |\n|3  |Robert   |          |Williams|42114     |M     |4000   |\n|4  |Maria    |Anne      |Jones   |39192     |F     |4000   |\n|5  |Jen      |Mary      |Brown   |          |F     |-1     |\n+---+---------+----------+--------+----------+------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, when\n",
    "\n",
    "data2 = [(\"1\",\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"2\",\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"3\",\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"4\",\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"5\",\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "  ]\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"ID\",StringType(),True), \\\n",
    "    StructField(\"FIRSTNAME\",StringType(),True), \\\n",
    "    StructField(\"MIDDLENAME\",StringType(),True), \\\n",
    "    StructField(\"LASTNAME\",StringType(),True), \\\n",
    "    StructField(\"ID_EMPRESA\", StringType(), True), \\\n",
    "    StructField(\"GENDER\", StringType(), True), \\\n",
    "    StructField(\"SALARIO\", IntegerType(), True) \\\n",
    "  ])\n",
    " \n",
    "df = spark.createDataFrame(data=data2,schema=schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5aad7155-9214-4268-8af3-a08c9547a186",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>FIRSTNAME</th><th>MIDDLENAME</th><th>LASTNAME</th><th>ID_EMPRESA</th><th>GENDER</th><th>SALARIO</th><th>NUEVA_SALARIO_10</th></tr></thead><tbody><tr><td>1</td><td>James</td><td></td><td>Smith</td><td>36636</td><td>M</td><td>3000</td><td>3300.0000000000005</td></tr><tr><td>2</td><td>Michael</td><td>Rose</td><td></td><td>40288</td><td>M</td><td>4000</td><td>4400.0</td></tr><tr><td>3</td><td>Robert</td><td></td><td>Williams</td><td>42114</td><td>M</td><td>4000</td><td>4400.0</td></tr><tr><td>4</td><td>Maria</td><td>Anne</td><td>Jones</td><td>39192</td><td>F</td><td>4000</td><td>4400.0</td></tr><tr><td>5</td><td>Jen</td><td>Mary</td><td>Brown</td><td>null</td><td>F</td><td>-1</td><td>-1.1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "James",
         "",
         "Smith",
         36636,
         "M",
         3000,
         3300.0000000000005
        ],
        [
         2,
         "Michael",
         "Rose",
         "",
         40288,
         "M",
         4000,
         4400.0
        ],
        [
         3,
         "Robert",
         "",
         "Williams",
         42114,
         "M",
         4000,
         4400.0
        ],
        [
         4,
         "Maria",
         "Anne",
         "Jones",
         39192,
         "F",
         4000,
         4400.0
        ],
        [
         5,
         "Jen",
         "Mary",
         "Brown",
         null,
         "F",
         -1,
         -1.1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "FIRSTNAME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "MIDDLENAME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "LASTNAME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ID_EMPRESA",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "GENDER",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "SALARIO",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "NUEVA_SALARIO_10",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result = df.withColumn(\"ID\",col(\"ID\").cast(\"int\"))\\\n",
    "    .withColumn(\"ID_EMPRESA\",col(\"ID_EMPRESA\").cast(\"INTEGER\"))\\\n",
    "    .withColumn(\"NUEVA_SALARIO_10\",col(\"SALARIO\") * 1.10)\n",
    "\n",
    "display(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e82d66e4-3320-4dad-a7c8-7483ceff8711",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>firstname</th><th>middlename</th><th>lastname</th><th>dob</th><th>gender</th><th>salary</th></tr></thead><tbody><tr><td>James</td><td></td><td>Smith</td><td>1991-04-01</td><td>M</td><td>3000</td></tr><tr><td>Michael</td><td>Rose</td><td></td><td>2000-05-19</td><td>M</td><td>4000</td></tr><tr><td>Robert</td><td></td><td>Williams</td><td>1978-09-05</td><td>M</td><td>4000</td></tr><tr><td>Maria</td><td>Anne</td><td>Jones</td><td>1967-12-01</td><td>F</td><td>4000</td></tr><tr><td>Jen</td><td>Mary</td><td>Brown</td><td>1980-02-17</td><td>F</td><td>-1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "James",
         "",
         "Smith",
         "1991-04-01",
         "M",
         3000
        ],
        [
         "Michael",
         "Rose",
         "",
         "2000-05-19",
         "M",
         4000
        ],
        [
         "Robert",
         "",
         "Williams",
         "1978-09-05",
         "M",
         4000
        ],
        [
         "Maria",
         "Anne",
         "Jones",
         "1967-12-01",
         "F",
         4000
        ],
        [
         "Jen",
         "Mary",
         "Brown",
         "1980-02-17",
         "F",
         -1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "firstname",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "middlename",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "lastname",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "dob",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [('James','','Smith','1991-04-01','M',3000),\n",
    "  ('Michael','Rose','','2000-05-19','M',4000),\n",
    "  ('Robert','','Williams','1978-09-05','M',4000),\n",
    "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
    "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "df = spark.createDataFrame(data=data, schema = columns)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5916c271-a90a-4746-a59d-8714cae34b0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|       dob|gender|salary|\n+---------+----------+--------+----------+------+------+\n|    James|          |   Smith|1991-04-01|     M|  3000|\n|  Michael|      Rose|        |2000-05-19|     M|  4000|\n|   Robert|          |Williams|1978-09-05|     M|  4000|\n|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n+---------+----------+--------+----------+------+------+\n\n+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|       dob|gender|salary|\n+---------+----------+--------+----------+------+------+\n|    James|          |   Smith|1991-04-01|     M|300000|\n|  Michael|      Rose|        |2000-05-19|     M|400000|\n|   Robert|          |Williams|1978-09-05|     M|400000|\n|    Maria|      Anne|   Jones|1967-12-01|     F|400000|\n|      Jen|      Mary|   Brown|1980-02-17|     F|  -100|\n+---------+----------+--------+----------+------+------+\n\n+---------+----------+--------+----------+------+------+------------+\n|firstname|middlename|lastname|       dob|gender|salary|CopiedColumn|\n+---------+----------+--------+----------+------+------+------------+\n|    James|          |   Smith|1991-04-01|     M|  3000|       -3000|\n|  Michael|      Rose|        |2000-05-19|     M|  4000|       -4000|\n|   Robert|          |Williams|1978-09-05|     M|  4000|       -4000|\n|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|       -4000|\n|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|           1|\n+---------+----------+--------+----------+------+------+------------+\n\n+---------+----------+--------+----------+---+------+\n|firstname|middlename|lastname|dob       |sex|salary|\n+---------+----------+--------+----------+---+------+\n|James    |          |Smith   |1991-04-01|M  |3000  |\n|Michael  |Rose      |        |2000-05-19|M  |4000  |\n|Robert   |          |Williams|1978-09-05|M  |4000  |\n|Maria    |Anne      |Jones   |1967-12-01|F  |4000  |\n|Jen      |Mary      |Brown   |1980-02-17|F  |-1    |\n+---------+----------+--------+----------+---+------+\n\n+---------+----------+--------+----------+------+\n|firstname|middlename|lastname|       dob|gender|\n+---------+----------+--------+----------+------+\n|    James|          |   Smith|1991-04-01|     M|\n|  Michael|      Rose|        |2000-05-19|     M|\n|   Robert|          |Williams|1978-09-05|     M|\n|    Maria|      Anne|   Jones|1967-12-01|     F|\n|      Jen|      Mary|   Brown|1980-02-17|     F|\n+---------+----------+--------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"salary\",col(\"salary\").cast(\"Integer\")).show()\n",
    "#Actualizar el valor existente\n",
    "df.withColumn(\"salary\",col(\"salary\")*100).show()\n",
    "#Crear una nueva columna a partir de una existente\n",
    "df.withColumn(\"CopiedColumn\",col(\"salary\")* -1).show()\n",
    "#Renombrar una columna\n",
    "df.withColumnRenamed(\"gender\",\"sex\") \\\n",
    "  .show(truncate=False) \n",
    "#Eliminar una columna\n",
    "df.drop(\"salary\").show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bdb8989-a21b-4098-af16-bf2046c99ee6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- dob: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n\n+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|dob       |gender|salary|\n+---------+----------+--------+----------+------+------+\n|James    |          |Smith   |1991-04-01|M     |3000  |\n|Michael  |Rose      |        |2000-05-19|M     |4000  |\n|Robert   |          |Williams|1978-09-05|M     |4000  |\n|Maria    |Anne      |Jones   |1967-12-01|F     |4000  |\n|Jen      |Mary      |Brown   |1980-02-17|F     |-1    |\n+---------+----------+--------+----------+------+------+\n\nroot\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- dob: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|dob       |gender|salary|\n+---------+----------+--------+----------+------+------+\n|James    |          |Smith   |1991-04-01|M     |3000  |\n|Michael  |Rose      |        |2000-05-19|M     |4000  |\n|Robert   |          |Williams|1978-09-05|M     |4000  |\n|Maria    |Anne      |Jones   |1967-12-01|F     |4000  |\n|Jen      |Mary      |Brown   |1980-02-17|F     |-1    |\n+---------+----------+--------+----------+------+------+\n\nroot\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- dob: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n\n+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|dob       |gender|salary|\n+---------+----------+--------+----------+------+------+\n|James    |          |Smith   |1991-04-01|M     |300000|\n|Michael  |Rose      |        |2000-05-19|M     |400000|\n|Robert   |          |Williams|1978-09-05|M     |400000|\n|Maria    |Anne      |Jones   |1967-12-01|F     |400000|\n|Jen      |Mary      |Brown   |1980-02-17|F     |-100  |\n+---------+----------+--------+----------+------+------+\n\nroot\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- dob: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- CopiedColumn: long (nullable = true)\n\nroot\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- dob: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- Country: string (nullable = false)\n\nroot\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- dob: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- Country: string (nullable = false)\n |-- anotherColumn: string (nullable = false)\n\n+---------+----------+--------+----------+---+------+\n|firstname|middlename|lastname|dob       |sex|salary|\n+---------+----------+--------+----------+---+------+\n|James    |          |Smith   |1991-04-01|M  |3000  |\n|Michael  |Rose      |        |2000-05-19|M  |4000  |\n|Robert   |          |Williams|1978-09-05|M  |4000  |\n|Maria    |Anne      |Jones   |1967-12-01|F  |4000  |\n|Jen      |Mary      |Brown   |1980-02-17|F  |-1    |\n+---------+----------+--------+----------+---+------+\n\n+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|dob       |gender|salary|\n+---------+----------+--------+----------+------+------+\n|James    |          |Smith   |1991-04-01|M     |3000  |\n|Michael  |Rose      |        |2000-05-19|M     |4000  |\n|Robert   |          |Williams|1978-09-05|M     |4000  |\n|Maria    |Anne      |Jones   |1967-12-01|F     |4000  |\n|Jen      |Mary      |Brown   |1980-02-17|F     |-1    |\n+---------+----------+--------+----------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit\n",
    "from pyspark.sql.types import StructType, StructField, StringType,IntegerType\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "data = [('James','','Smith','1991-04-01','M',3000),\n",
    "  ('Michael','Rose','','2000-05-19','M',4000),\n",
    "  ('Robert','','Williams','1978-09-05','M',4000),\n",
    "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
    "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data=data, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "df2 = df.withColumn(\"salary\",col(\"salary\").cast(\"Integer\"))\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)\n",
    "\n",
    "df3 = df.withColumn(\"salary\",col(\"salary\")*100)\n",
    "df3.printSchema()\n",
    "df3.show(truncate=False) \n",
    "\n",
    "df4 = df.withColumn(\"CopiedColumn\",col(\"salary\")* -1)\n",
    "df4.printSchema()\n",
    "\n",
    "df5 = df.withColumn(\"Country\", lit(\"USA\"))\n",
    "df5.printSchema()\n",
    "\n",
    "df6 = df.withColumn(\"Country\", lit(\"USA\")) \\\n",
    "   .withColumn(\"anotherColumn\",lit(\"anotherValue\"))\n",
    "df6.printSchema()\n",
    "\n",
    "df.withColumnRenamed(\"gender\",\"sex\") \\\n",
    "  .show(truncate=False) \n",
    "  \n",
    "df4.drop(\"CopiedColumn\") \\\n",
    ".show(truncate=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a70ffa6-a653-4ccc-ba7c-ed81879507c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- employee_name: string (nullable = true)\n |-- department: string (nullable = true)\n |-- salary: long (nullable = true)\n\n+-------------+----------+------+\n|employee_name|department|salary|\n+-------------+----------+------+\n|James        |Sales     |3000  |\n|Michael      |Sales     |4600  |\n|Robert       |Sales     |4100  |\n|Maria        |Finance   |3000  |\n|James        |Sales     |3000  |\n|Scott        |Finance   |3300  |\n|Jen          |Finance   |3900  |\n|Jeff         |Marketing |3000  |\n|Kumar        |Marketing |2000  |\n|Saif         |Sales     |4100  |\n+-------------+----------+------+\n\nDistinct count: 9\n+-------------+----------+------+\n|employee_name|department|salary|\n+-------------+----------+------+\n|James        |Sales     |3000  |\n|Michael      |Sales     |4600  |\n|Robert       |Sales     |4100  |\n|Maria        |Finance   |3000  |\n|Scott        |Finance   |3300  |\n|Jen          |Finance   |3900  |\n|Jeff         |Marketing |3000  |\n|Kumar        |Marketing |2000  |\n|Saif         |Sales     |4100  |\n+-------------+----------+------+\n\nDistinct count: 9\n+-------------+----------+------+\n|employee_name|department|salary|\n+-------------+----------+------+\n|James        |Sales     |3000  |\n|Michael      |Sales     |4600  |\n|Robert       |Sales     |4100  |\n|Maria        |Finance   |3000  |\n|Scott        |Finance   |3300  |\n|Jen          |Finance   |3900  |\n|Jeff         |Marketing |3000  |\n|Kumar        |Marketing |2000  |\n|Saif         |Sales     |4100  |\n+-------------+----------+------+\n\nDistinct count of department salary : 8\n+-------------+----------+------+\n|employee_name|department|salary|\n+-------------+----------+------+\n|Maria        |Finance   |3000  |\n|Scott        |Finance   |3300  |\n|Jen          |Finance   |3900  |\n|Kumar        |Marketing |2000  |\n|Jeff         |Marketing |3000  |\n|James        |Sales     |3000  |\n|Robert       |Sales     |4100  |\n|Michael      |Sales     |4600  |\n+-------------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "data = [(\"James\", \"Sales\", 3000), \\\n",
    "    (\"Michael\", \"Sales\", 4600), \\\n",
    "    (\"Robert\", \"Sales\", 4100), \\\n",
    "    (\"Maria\", \"Finance\", 3000), \\\n",
    "    (\"James\", \"Sales\", 3000), \\\n",
    "    (\"Scott\", \"Finance\", 3300), \\\n",
    "    (\"Jen\", \"Finance\", 3900), \\\n",
    "    (\"Jeff\", \"Marketing\", 3000), \\\n",
    "    (\"Kumar\", \"Marketing\", 2000), \\\n",
    "    (\"Saif\", \"Sales\", 4100) \\\n",
    "  ]\n",
    "columns= [\"employee_name\", \"department\", \"salary\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "#Distinct\n",
    "distinctDF = df.distinct()\n",
    "print(\"Distinct count: \"+str(distinctDF.count()))\n",
    "distinctDF.show(truncate=False)\n",
    "\n",
    "#Drop duplicates\n",
    "df2 = df.dropDuplicates()\n",
    "print(\"Distinct count: \"+str(df2.count()))\n",
    "df2.show(truncate=False)\n",
    "\n",
    "#Drop duplicates on selected columns\n",
    "dropDisDF = df.dropDuplicates([\"department\",\"salary\"])\n",
    "print(\"Distinct count of department salary : \"+str(dropDisDF.count()))\n",
    "dropDisDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8237d1b0-614d-4ea4-844b-fb46c425b6f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- employee_name: string (nullable = true)\n |-- department: string (nullable = true)\n |-- state: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- age: long (nullable = true)\n |-- bonus: long (nullable = true)\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|James        |Sales     |NY   |90000 |34 |10000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|James        |Sales     |NY   |90000 |34 |10000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|James        |Sales     |NY   |90000 |34 |10000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|James        |Sales     |NY   |90000 |34 |10000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n+-------------+----------+-----+------+---+-----+\n\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, asc, desc\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000), \\\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,20000), \\\n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30,23000), \\\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000), \\\n",
    "    (\"Raman\",\"Finance\",\"CA\",99000,40,24000), \\\n",
    "    (\"Scott\",\"Finance\",\"NY\",83000,36,19000), \\\n",
    "    (\"Jen\",\"Finance\",\"NY\",79000,53,15000), \\\n",
    "    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000), \\\n",
    "    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000) \\\n",
    "  ]\n",
    "columns= [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "\n",
    "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "df.sort(\"department\",\"state\").show(truncate=False)\n",
    "df.sort(col(\"department\"),col(\"state\")).show(truncate=False)\n",
    "\n",
    "df.orderBy(\"department\",\"state\").show(truncate=False)\n",
    "df.orderBy(col(\"department\"),col(\"state\")).show(truncate=False)\n",
    "\n",
    "df.sort(df.department.asc(),df.state.asc()).show(truncate=False)\n",
    "df.sort(col(\"department\").asc(),col(\"state\").asc()).show(truncate=False)\n",
    "df.orderBy(col(\"department\").asc(),col(\"state\").asc()).show(truncate=False)\n",
    "\n",
    "df.sort(df.department.asc(),df.state.desc()).show(truncate=False)\n",
    "df.sort(col(\"department\").asc(),col(\"state\").desc()).show(truncate=False)\n",
    "df.orderBy(col(\"department\").asc(),col(\"state\").desc()).show(truncate=False)\n",
    "\n",
    "df.createOrReplaceTempView(\"EMP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60136221-c4c0-4274-b6a3-f596490d8457",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n+-------------+----------+-----+------+---+-----+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select employee_name,department,state,salary,age,bonus from EMP ORDER BY department asc\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2a9c881-d0b1-402f-ab0d-8b3de803f867",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- employee_name: string (nullable = true)\n |-- department: string (nullable = true)\n |-- state: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- age: long (nullable = true)\n |-- bonus: long (nullable = true)\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n+-------------+----------+-----+------+---+-----+\n\n+----------+-----------+\n|department|sum(salary)|\n+----------+-----------+\n|Sales     |257000     |\n|Finance   |351000     |\n|Marketing |171000     |\n+----------+-----------+\n\n+----------+-----+\n|department|count|\n+----------+-----+\n|Sales     |3    |\n|Finance   |4    |\n|Marketing |2    |\n+----------+-----+\n\n+----------+-----+-----------+----------+\n|department|state|sum(salary)|sum(bonus)|\n+----------+-----+-----------+----------+\n|Sales     |NY   |176000     |30000     |\n|Sales     |CA   |81000      |23000     |\n|Finance   |CA   |189000     |47000     |\n|Finance   |NY   |162000     |34000     |\n|Marketing |NY   |91000      |21000     |\n|Marketing |CA   |80000      |18000     |\n+----------+-----+-----------+----------+\n\n+----------+----------+-----------------+---------+---------+\n|department|sum_salary|avg_salary       |sum_bonus|max_bonus|\n+----------+----------+-----------------+---------+---------+\n|Sales     |257000    |85666.66666666667|53000    |23000    |\n|Finance   |351000    |87750.0          |81000    |24000    |\n|Marketing |171000    |85500.0          |39000    |21000    |\n+----------+----------+-----------------+---------+---------+\n\n+----------+----------+-----------------+---------+---------+\n|department|sum_salary|avg_salary       |sum_bonus|max_bonus|\n+----------+----------+-----------------+---------+---------+\n|Sales     |257000    |85666.66666666667|53000    |23000    |\n|Finance   |351000    |87750.0          |81000    |24000    |\n+----------+----------+-----------------+---------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col,sum,avg,max\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000),\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,20000),\n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30,23000),\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000),\n",
    "    (\"Raman\",\"Finance\",\"CA\",99000,40,24000),\n",
    "    (\"Scott\",\"Finance\",\"NY\",83000,36,19000),\n",
    "    (\"Jen\",\"Finance\",\"NY\",79000,53,15000),\n",
    "    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000),\n",
    "    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000)\n",
    "  ]\n",
    "\n",
    "schema = [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "df.groupBy(\"department\").sum(\"salary\").show(truncate=False)\n",
    "\n",
    "df.groupBy(\"department\").count().show(truncate=False)\n",
    "\n",
    "\n",
    "df.groupBy(\"department\",\"state\") \\\n",
    "    .sum(\"salary\",\"bonus\") \\\n",
    "   .show(truncate=False)\n",
    "\n",
    "df.groupBy(\"department\") \\\n",
    "    .agg(sum(\"salary\").alias(\"sum_salary\"), \\\n",
    "         avg(\"salary\").alias(\"avg_salary\"), \\\n",
    "         sum(\"bonus\").alias(\"sum_bonus\"), \\\n",
    "         max(\"bonus\").alias(\"max_bonus\") \\\n",
    "     ) \\\n",
    "    .show(truncate=False)\n",
    "    \n",
    "df.groupBy(\"department\") \\\n",
    "    .agg(sum(\"salary\").alias(\"sum_salary\"), \\\n",
    "      avg(\"salary\").alias(\"avg_salary\"), \\\n",
    "      sum(\"bonus\").alias(\"sum_bonus\"), \\\n",
    "      max(\"bonus\").alias(\"max_bonus\")) \\\n",
    "    .where(col(\"sum_bonus\") >= 50000) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8afc58ff-bf3c-47b9-8f9d-0dd85ef75238",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f886e23d-9cb8-4aa8-965d-ac856305b83a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b279a78-236c-4797-870a-ee86be7afe4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c3c3402-708e-4e20-9811-7150ff522e57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6a6b046-69d6-46a1-913e-e16b12d56999",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Spark01 MIK 2025-07-08 15:32:54",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}